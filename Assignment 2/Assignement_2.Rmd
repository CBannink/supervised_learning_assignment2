---
title: "Assignment 2"
author: "Iris van Engen, Sara Claus, Caspar Bannink, Wessel Brouwer"
output: html_document
date: "2023-10-25"
editor_options: 
  markdown: 
    wrap: 72
---

Libraries:

```{r}
library(ggplot2)
library(tidyverse) 
library(viridis)
library(ggpubr)
library(rpart)
library(psych)
library(rpart.plot)
library(randomForest)
library(magrittr)
library(caret)
library(corrplot)
library(pROC)
```

# Introducing the dataset

To do:\
- choose a dataset\
- clean dataset - explain dataset - introduce what question we want to
answer (so what is the dependent variable and are the independent
variables)

# Representing the data

Content: make few interesting plots

# Simple model

To do: - Make a simple model - Explain model method (linear
regression?) - Create confusion matrix - Explain de predictions (which
are the truly true, falsly true etc) - Evaluate the performance of the
model

# Importing dataset

```{r}
# Importing datasets 
red_wine <- read.csv("wine+quality/winequality-red.csv", sep = ";")
white_wine <- read.csv("wine+quality/winequality-white.csv", sep = ";")
white_wine %>%  mutate(quality = as.factor(quality))
```

```{r}
summary(white_wine)
```

# Introducing dataset

This dataset from Cortez et al.,2009 contains information of 4898 types
of white wine. For each wine, 12 measurements have been gathered and
collected in this dataset. The dataset contains the following
variables. - Fixed acidity, grams of tartaric acids per liter - Volatile
acidity, grams of acetic acid per liter - citric acid, in gram per
liter - residual sugar, the amount of leftover sugar in the wine bottle
in gram per liter - chlorides, grams of sodium chloride per liter - free
sulfur dioxides, in milligram per liter - total sulfur dioxides, in
milligram per liter - density, is the grams per mililiter - pH, measure
for the acidity of a wine. A pH below 7 meaning that it is considered
acidic, a pH above 7 is considered basic. - sulphates, grams of
potassium sulphate per liter - alcohol, percentage of alcohol of total
wine volume. - quality, a number from 1 to 10 to rate the taste of wine
based on triplicate blinde taste test.

We want to be able to predict based on above described physiochemical
properties whether a wine will be of good quality or not. To get an idea
of the differences in physiochemical properties between different
quality-ratings, we summarized the medians of all variables grouped by
quality.

#Exploratory Data Analysis (EDA)
To gain insights into the dataset, we first performed exploratory data analysis. We created summary statistics, distribution plots, and boxplots to understand the distribution of quality ratings and the relationships between different physiochemical properties.

```{r}
white_wine %>% 
  group_by(quality) %>% 
  summarise(n_observations = length(quality),
            median_alcohol = median(alcohol),
            median_chorides = median(chlorides),
            median_density = median(density), 
            median_pH = median(pH),
            median_sulphates = median(sulphates), 
            median_fixed_acidity = median(fixed.acidity),
            median_volatile_acidity = median(volatile.acidity),
            median_total.sulfur.dioxide = median(total.sulfur.dioxide),
            median_free.sulfur.dioxide = median(free.sulfur.dioxide),
            median_citric.acid = median(citric.acid),
            median_residual.sugar = median(residual.sugar))
```

The majority of wines are scored within 5-7 range. Only very few wines
could be considered bad (3-4) and only few wines could be considered
good (8-9) wines.

```{r}
white_wine %>% 
  ggplot(aes(x = quality))+ 
  geom_bar()+
  labs(xlab = "quality",
       ylab = "count",
       title = "Distribution of wine quality")+
  theme_minimal()
  
```

Based on the table with median values grouped by quality score, we do
not have a clear idea of what influences the quality of white wines. To
get a better idea, we plotted quality score grouped boxplots for all
variables.

```{r}
make_box <- function(y_data, y_labs){
  white_wine %>% ggplot(aes(y = y_data)) + 
    geom_boxplot(fill = "sea green") +
    facet_wrap(~quality, ncol = 7) +
    ylab(y_labs) +
    theme(axis.text.x = element_blank())
}

box_alc <- make_box(white_wine$alcohol, "Alcohol %")
box_chl <- make_box(white_wine$chlorides, "Ahlorides")
box_free_so2 <- make_box(white_wine$free.sulfur.dioxide, "Free sulfur dioxide")
box_tot_so2 <- make_box(white_wine$total.sulfur.dioxide, "Total sulfur dioxide")
box_fix_acid <- make_box(white_wine$fixed.acidity, "Fixed acidity")
box_vol_acid <- make_box(white_wine$volatile.acidity, "volatile acidity")
box_cit_acid <- make_box(white_wine$citric.acid, "Citric acid")
box_res_sug <- make_box(white_wine$residual.sugar, "Residual sugar")
box_pH <- make_box(white_wine$pH, "pH")
box_dens <- make_box(white_wine$density, "Density")
box_sulp <- make_box(white_wine$sulphates, "Sulphates")

fig2 <- ggarrange(box_cit_acid,box_vol_acid,box_fix_acid,box_tot_so2,box_free_so2, labels = c("F","G","H","I","J","K"), ncol = 3, nrow = 2)
fig1 <- ggarrange(box_alc,box_dens, box_pH, box_chl,box_res_sug, box_sulp,labels = c("A","B","C","D","E"), ncol = 3, nrow = 2)

annotate_figure(fig1, top = text_grob("Boxplots of physiochemical properties of wine",color = "black", face = "bold", size = 14),
                fig.lab = "Figure 1", fig.lab.face = "bold")

annotate_figure(fig2, top = text_grob("Boxplots of physiochemical properties of wine",color = "black", face = "bold", size = 14),
                fig.lab = "Figure 2", fig.lab.face = "bold")

```

The boxplots show, that apart from alcohol percentage, there is not much
difference going up or down single quality scores. Estimating quality
accurate would be hard and unnecessary. Therefore, we will make a model
that is able to classify bad and good from each other.

```{r}
white_wine_duplicated <- white_wine %>% 
  mutate(group = factor(ifelse(quality < 6, "Bad", "Good")))
white_wine <- white_wine %>% 
  mutate(group = factor(ifelse(quality < 7, "Bad", "Good")))


make_box_1 <- function(y_data, y_labs){
  white_wine %>% ggplot(aes(y = y_data)) + 
    geom_boxplot(fill = "sea green") +
    facet_wrap(~group) +
    ylab(y_labs) +
    theme(axis.text.x = element_blank())
}


box_alc_1 <- make_box_1(white_wine$alcohol, "alcohol %")
box_chl_1 <- make_box_1(white_wine$chlorides, "chlorides")
box_free_so2_1 <- make_box_1(white_wine$free.sulfur.dioxide, "Free sulfur dioxide")
box_tot_so2_1 <- make_box_1(white_wine$total.sulfur.dioxide, "Total sulfur dioxide")
box_fix_acid_1 <- make_box_1(white_wine$fixed.acidity, "Fixed acidity")
box_vol_acid_1 <- make_box_1(white_wine$volatile.acidity, "volatile acidity")
box_cit_acid_1 <- make_box_1(white_wine$citric.acid, "Citric acid")
box_res_sug_1 <- make_box_1(white_wine$residual.sugar, "Residual sugar")
box_pH_1 <- make_box_1(white_wine$pH, "pH")
box_dens_1 <- make_box_1(white_wine$density, "Density")
box_sulp_1 <- make_box_1(white_wine$sulphates, "Sulphates")



fig2 <- ggarrange(box_cit_acid_1,box_vol_acid_1,box_fix_acid_1,box_tot_so2_1,box_free_so2_1, labels = c("F","G","H","I","J","K"), ncol = 3, nrow = 2)
fig1 <- ggarrange(box_alc_1,box_dens_1, box_pH_1, box_chl_1,box_res_sug_1, box_sulp_1,labels = c("A","B","C","D","E"), ncol = 3, nrow = 2)

annotate_figure(fig1, top = text_grob("Boxplots of physiochemical properties of wine",color = "black", face = "bold", size = 14),
                fig.lab = "Figure 1", fig.lab.face = "bold")

annotate_figure(fig2, top = text_grob("Boxplots of physiochemical properties of wine",color = "black", face = "bold", size = 14),
                fig.lab = "Figure 2", fig.lab.face = "bold")

```

Since it is not possible to pinpoint a single feature that highly
influences the quality of white wine based on visualization, we explored the correlation matrix to understand the relationships between different physiochemical features.

```{r}
cor_matrix <- cor(white_wine[,c(1:12)])
cor_matrix
```
To better visualize the correlation between the features we construct a correlogram.


```{r}
corrplot(cor_matrix, type = "upper",  
         method = "square",  
         addCoef.col = "black", 
         tl.cex = 0.6,
         number.cex = 0.6,
         tl.col = "black", tl.srt = 45,
         )
```

 In the following plots we investigate relationships between different variables, and color points by quality for comparison.

```{r}
white_wine %>% 
  ggplot(aes(x = volatile.acidity, y = fixed.acidity, color = quality))+ 
  geom_point()+
  scale_color_viridis()+
  labs(xlab = "volatile acidity",
       ylab = "fixed acidity",
       title = "Effect of acidity on quality")+
  theme_minimal()+ 
  facet_wrap(.~ group)

```

```{r}
white_wine %>% 
  ggplot(aes(x = pH, y = citric.acid, color = quality))+ 
  geom_point()+
  scale_color_viridis()+
  labs(xlab = "volatile acidity",
       ylab = "Citric acidity",
       title = "Effect of acidity on quality")+
  theme_minimal()+ 
  facet_wrap(.~ group)
```

```{r}
white_wine %>% 
  ggplot(aes(x = density, y = alcohol, color = quality))+ 
  geom_point(aes(alpha = 0.8))+
  scale_color_viridis()+
  labs(xlab = "density",
       ylab = "alcohol",
       title = "Effect of alcohol % on quality")+
  theme_minimal()+ 
  facet_wrap(.~ group)
```

#Models

First we set a seed.
```{r}
#caspar Bannink
set.seed(123)
```

Then we divide the data into a Train and a Test set, for which the proportion is 90% Train and 10% Test. 
```{r}
white_wine <- white_wine %>% 
  select(!(quality)) 
white_wine <- white_wine %>% 
  mutate(split = sample(c(rep("Test",490), rep("Train", 4408))))
```

As seen in the previous graph get an even distribution of the instances with quality group "Bad" and quality group "Good" we duplicate the instances of the group "Bad"
```{r}
bad_indices <- which(white_wine_duplicated$group == "Bad")

# Duplicate the "Bad" class instances
duplicated_data <- white_wine_duplicated[bad_indices, ]

# Combine the duplicated instances with the original dataset
balanced_data <- rbind(white_wine_duplicated, duplicated_data)
white_wine_duplicated <- balanced_data
white_wine_duplicated <- white_wine_duplicated %>% 
  select(!(quality)) 
white_wine_duplicated <- white_wine_duplicated %>% 
  mutate(split = sample(c(rep("Test",653), rep("Train", 5885))))

#all datasets (dataset with bad classification if <7 or <6 but with bad instances duplicated for even distribution)
wwTrain <- white_wine %>% filter(split =="Train") %>%subset(select = -split)
wwTest <- white_wine %>% filter(split =="Test") %>% subset(select=-split)
wwTrain_duplicated <- white_wine_duplicated %>% filter(split =="Train") %>% subset(select = -split)
wwTest_duplicated <- white_wine_duplicated %>% filter(split =="Test") %>% subset(select= -split)

ncol_train <- ncol(wwTrain)
ncol_train_duplicated <- ncol(wwTrain_duplicated)
```

#Simple model
We started by building a simple model using a decision tree classifier. The dataset was split into training and testing sets, and the model was trained using 10-fold cross-validation.

```{r}
#simple models grid search
grid_simple <- expand.grid(cp = c(0.01, 0.001, 1, 0.1))
model_simple <- train(group ~ ., data = wwTrain, method = "rpart", trControl = trainControl(method = "repeatedcv",number = 10, repeats = 3), metric = "Accuracy", tuneGrid = grid_simple)
model_simple_duplicated <- train(group ~ ., data = wwTrain_duplicated, method = "rpart", trControl = trainControl(method = "repeatedcv",number = 10, repeats = 3), metric="Accuracy", tuneGrid = grid_simple)
```

```{r}
#choose the best model with settings
best_model_simple <- model_simple$finalModel
best_model_simple_duplicated <- model_simple_duplicated$finalModel
```

All models output probabilites, however, this is not of good use for comparing accuracies, we want correct classifications
```{r}
#this function converts probabilities to classes, threshold can be set to improve overal accuracy if (experiment)
probToClass <- function(pred){
  pred <- data.frame(pred)
  result_df <- data.frame(predicted_class = ifelse(pred$Good >= 0.5, "Good", "Bad"))
  return(result_df)
}

#convert classes and target classes to an accuracy measure
getAcc <- function(target_class, pred_class){
  return(mean(target_class == pred_class))
}
```

Predictions for the simple method

```{r}
predictions_simple <- predict(best_model_simple, wwTest) %>% probToClass()
predictions_simple_duplicated <- predict(best_model_simple_duplicated, wwTest_duplicated) %>% probToClass()
```

Accuracy

```{r}
cat("Accuracy predictions simple model:", getAcc(wwTest$group,predictions_simple$predicted_class), "\n") #accuracy of simple the model on dataset with good>7.0
cat("Accuracy predictions simple model with dublicates:", getAcc(wwTest_duplicated$group,predictions_simple_duplicated$predicted_class), "\n") #accuracy of the simple model with duplicated data
```

Confusion matrix

```{r}
#confusion matrix simple model
factor_vector <- c("Bad", "Good")
predictions_simple$predicted_class <- factor(predictions_simple$predicted_class,levels=factor_vector)
wwTest$group <- factor(wwTest$group,levels=factor_vector)
wwTest_duplicated$group <- factor(wwTest_duplicated$group,levels=factor_vector)
predictions_simple_duplicated$predicted_class <- factor(predictions_simple_duplicated$predicted_class,levels=factor_vector)

simple_model_confusion_matrix <- confusionMatrix(predictions_simple$predicted_class,wwTest$group) 
simple_model_confusion_matrix_duplicated <- confusionMatrix(predictions_simple_duplicated$predicted_class,wwTest_duplicated$group) #confusion matrix simple model duplicated

simple_model_confusion_matrix
simple_model_confusion_matrix_duplicated
```
With this confusion matrix we can plot a POC curve. As can be seen in the plot the AUC is 0.735 for the simple model. 

```{r}
roc_simple <- roc(response = wwTest$group, predictor = as.numeric(predictions_simple$predicted_class == "Good"))
plot(roc_simple, col = "blue", print.auc = TRUE, auc.polygon = TRUE, main = "ROC Curve - Simple Model")
```




#Complex model
For the improvement of the simpler model we use two random forest models, which we train with gridsearch to find the best hyperparameter settings. 

```{r}
#complicated models first 2 random forest, train with gridsearch for best hyperparameter settings
grid <- expand.grid(mtry = c(ncol_train-1, sqrt(ncol_train), ncol_train/2))
model <- train(group ~ ., data = wwTrain, method = "rf", trControl = trainControl(method = "repeatedcv", number=10, repeats = 3), tuneGrid =grid, metric="Accuracy")
model_duplicated <- train(group ~ ., data = wwTrain_duplicated, method = "rf", trControl = trainControl(method = "repeatedcv", number=10, repeats = 3), tuneGrid =grid, metric="Accuracy")
```

#choose the best model with settings
```{r}
best_model <- model$finalModel
best_model_duplicated <- model_duplicated$finalModel
```

Predictions for the complex method

```{r}
predictions <- predict(best_model, wwTest)  
predictions_duplicated <- predict(best_model_duplicated, wwTest_duplicated) 
```

Accuracy

```{r}
cat("Accuracy predictions complex model:", getAcc(wwTest$group,predictions), "\n") #accuracy of complex model good>7.0
cat("Accuracy predictions complex model with duplicates:", getAcc(wwTest_duplicated$group,predictions_duplicated), "\n") #acc of complex model duplicated data
```


To asses the performance of the model, we look at the confusion matrix.

```{r}
#confusion matrix complex model
model_confusion_matrix <- confusionMatrix(predictions,wwTest$group) 
model_confusion_dubplicated <- confusionMatrix(predictions_duplicated,wwTest_duplicated$group) #confusion matrix complex model duplicated


model_confusion_dubplicated
model_confusion_matrix
```
With this confusion matrix we can plot a POC curve

```{r}
roc_complex <- roc(response = wwTest_duplicated$group, predictor = as.numeric(predictions_duplicated == "Good"))
plot(roc_complex, col = "blue", print.auc = TRUE, auc.polygon = TRUE, main = "ROC Curve - Simple Model")
```
#Conclusion

In conclusion, both models were able to predict wine quality to some extent, with the complex model outperforming the simple model. The ROC curves and AUC values indicate the trade-off between sensitivity and specificity. 
